{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/brainx/__init__.py:30: UserWarning: Monkeypatching NetworkX's Watts-Strogatz routine\n",
      "  warnings.warn(\"Monkeypatching NetworkX's Watts-Strogatz routine\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import brainmaptools as brainmap\n",
    "import matplotlib.pyplot as plt\n",
    "import community\n",
    "import brainx.modularity as mod\n",
    "import operator\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import scipy as scipy\n",
    "import scipy.io as io\n",
    "import scipy.stats as stats\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "import math as math\n",
    "import pylab as pl\n",
    "import My_functions as myfunctions\n",
    "import progressbar as pb\n",
    "import time\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "%load_ext Cython\n",
    "import bct\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domains= ['Memory', 'Working Memory', 'Emotion', 'Attention', 'Language', 'Vision', 'Audition']\n",
    "domainsfile=\"/Users/owner/Functional_Connectivity/Results/studies_filtered_by_domain.pck\"\n",
    "domaindata=pickle.load(open(domainsfile, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_codes=brainmap.build_key_codes_from_workspaces(workspaces, datadir)\n",
    "domain_filtered_keycodes=dict()\n",
    "for x in domains:\n",
    "    domain_filtered_keycodes[x]=brainmap.domain_filter_keycodes(key_codes,domaindata,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domains.append('Base')\n",
    "domain_filtered_keycodes['Base']=key_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relabel_dict_file='/Users/owner/Functional_Connectivity/Scripts/Label_dict.pck'\n",
    "relabel_dict=pickle.load(open(relabel_dict_file,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_nothresh={}\n",
    "for x in domains:\n",
    "    filename='G_nothresh_jaccard_'+x+'_.pck'\n",
    "    workdir='/Users/owner/Functional_Connectivity/Results/G_jaccard_graphs/Unthresholded_G_jaccard/'\n",
    "    output=workdir+filename\n",
    "    G_nothresh[x]=pickle.load(open (output, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Influence Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "influence_G={}\n",
    "influence_matrix={}\n",
    "for x in domains: \n",
    "    influence_matrix[x]=brainmap.build_influence_digraph(brainmap.build_n_coactives_array(domain_filtered_keycodes[x]))\n",
    "    influence_G[x]=nx.relabel_nodes(influence_matrix[x],relabel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directed_edge=pd.DataFrame(nx.to_numpy_matrix(influence_G['Base']))\n",
    "directed_edge.to_csv('/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/EdgeFiles/Influence/CSV/Influence_edge.csv', header=False, index=False, index_label=False)\n",
    "csv_file = '/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/EdgeFiles/Influence/CSV/Influence_edge.csv'\n",
    "txt_file = '/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/EdgeFiles/Influence/Edges/Influence_edge.edge'\n",
    "with open(txt_file, \"w\") as my_output_file:\n",
    "    with open(csv_file, \"r\") as my_input_file:\n",
    "        [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "    my_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_influencers={node: len(influence_G['Base'].predecessors(node)) for node in influence_G['Base'].nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_successors={node: len(influence_G['Base'].successors(node)) for node in influence_G['Base'].nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compiled_list=[]\n",
    "for region in relabel_dict.values():\n",
    "    compiled_list.append(region[:-1])\n",
    "compiled_list=set(compiled_list)\n",
    "compiled_list=[x for x in compiled_list if not any(c.isdigit() for c in x)]\n",
    "compiled_list=sorted(compiled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compiled_region_dict={}\n",
    "for substring in compiled_list:\n",
    "    for region in relabel_dict.values():\n",
    "        if substring in region:\n",
    "            compiled_region_dict.setdefault(substring, []).append(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "successor_dict={node: influence_G['Base'].successors(node) for node in influence_G['Base'].nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for influencer in successor_dict.keys():\n",
    "    successor_dict[influencer].append(influencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_region_dict={}\n",
    "for key in compiled_region_dict.keys():\n",
    "    for subregion in successor_dict.keys():\n",
    "        if key in subregion:\n",
    "            parent_region_dict.setdefault(key, []).append(successor_dict[subregion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_final ={parent: [item for sublist in parent_region_dict[parent] for item in sublist] for parent in parent_region_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subnetwork={parent: influence_G['Base'].subgraph(set(parent_final[parent])) for parent in parent_final.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for parent in compiled_region_dict.keys():\n",
    "    for edge in subnetwork[parent].edges():\n",
    "        if parent not in edge[0] and parent not in edge[1]:\n",
    "            subnetwork[parent].remove_edge(edge[0], edge[1])\n",
    "            brainmap.remove_edgeless_nodes(subnetwork[parent])\n",
    "        for subregion in subnetwork[parent].nodes():\n",
    "            if parent in subregion:\n",
    "                for pred in subnetwork[parent].predecessors(subregion):\n",
    "                    subnetwork[parent].remove_edge(pred, subregion)\n",
    "                    brainmap.remove_edgeless_nodes(subnetwork[parent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Create Version Put Through Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh=[0.06, 0.07, 0.08, 0.09, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subnet_cost={parent: {cost: brainmap.applycost_to_g(influence_G['Base'], cost) for cost in thresh} for parent in subnetwork.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for parent in subnet_cost.keys():\n",
    "    for cost in subnet_cost[parent].keys():\n",
    "        for edge in subnet_cost[parent][cost].edges():\n",
    "            if parent not in edge[0] and parent not in edge[1]:\n",
    "                subnet_cost[parent][cost].remove_edge(edge[0], edge[1])\n",
    "                brainmap.remove_edgeless_nodes(subnet_cost[parent][cost])\n",
    "            for subregion in subnet_cost[parent][cost].nodes():\n",
    "                if parent in subregion:\n",
    "                    for pred in subnet_cost[parent][cost].predecessors(subregion):\n",
    "                        subnet_cost[parent][cost].remove_edge(pred, subregion)\n",
    "                        brainmap.remove_edgeless_nodes(subnet_cost[parent][cost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataf=pd.read_csv('/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/NodeFiles/CSV/Label_coordinates.csv', header=None, names=['x','y','z','regions'])\n",
    "dataf.insert(4,'type',0,True)\n",
    "dataf.insert(5,'size',0,True)\n",
    "dataf.insert(6,'nodes',0,True)\n",
    "dataf=dataf[['x','y','z','type','size','regions','nodes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "influencedf={parent: {cost: pd.read_csv('/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/NodeFiles/CSV/Label_coordinates.csv', header=None, names=['x','y','z','regions']) for cost in subnet_cost[parent].keys()} for parent in subnet_cost.keys()}\n",
    "sortnodes={parent: {cost: dict(zip(subnet_cost[parent][cost].nodes(),range(subnet_cost[parent][cost].number_of_nodes()))) for cost in subnet_cost[parent].keys()} for parent in subnet_cost.keys()}\n",
    "for parent in subnet_cost.keys():\n",
    "    for cost in subnet_cost[parent].keys():\n",
    "        influencedf[parent][cost]=pd.read_csv('/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/NodeFiles/CSV/Label_coordinates.csv', header=None, names=['x','y','z','regions'])\n",
    "        influencedf[parent][cost].insert(4,'type',0,True)\n",
    "        influencedf[parent][cost].insert(5,'size',0,True)\n",
    "        influencedf[parent][cost].insert(6,'nodes',0,True)\n",
    "        influencedf[parent][cost]=influencedf[parent][cost][['x','y','z','type','size','regions','nodes']]\n",
    "        for region in subnet_cost[parent][cost].nodes():\n",
    "            for n in range(len(influencedf[parent][cost])):\n",
    "                if region == influencedf[parent][cost].loc[n,'regions']:\n",
    "                    influencedf[parent][cost].loc[n,'nodes']=region\n",
    "                    influencedf[parent][cost].loc[n, 'size']=0\n",
    "                    if parent in region:\n",
    "                        influencedf[parent][cost].loc[n, 'type']=1\n",
    "        influencedf[parent][cost]=influencedf[parent][cost][['x','y','z','type','size','nodes']]\n",
    "        influencedf[parent][cost]=influencedf[parent][cost][influencedf[parent][cost].nodes != 0]\n",
    "        influencedf[parent][cost]['sorted_nodes']=influencedf[parent][cost]['nodes'].map(sortnodes[parent][cost])\n",
    "        influencedf[parent][cost].sort_values(['sorted_nodes'], ascending=True, inplace=True)\n",
    "        influencedf[parent][cost].drop('sorted_nodes', 1, inplace=True)\n",
    "        influencedf[parent][cost].index=range(len(influencedf[parent][cost]))\n",
    "        outdir='/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/NodeFiles/Influence/CSV/'\n",
    "        if influencedf[parent][cost].empty == True:\n",
    "            print ('{} Dataframe at cost {} is empty.'.format(parent, cost))\n",
    "        else:\n",
    "            filename=parent+str(cost)+'_Influences.csv'\n",
    "            influencedf[parent][cost].to_csv(outdir+filename, header=False, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create BrainNet File of Influence Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for parent in subnet_cost.keys():\n",
    "    for cost in subnet_cost[parent].keys():\n",
    "        csv_file ='/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/NodeFiles/Influence/CSV/'+parent+str(cost)+'_Influences.csv'\n",
    "        if os.path.isfile(csv_file):\n",
    "            txt_file = '/Users/owner/Desktop/BrainImagingViewer/BrainNetViewer_20171031/Data/NodeFiles/Influence/'+parent+str(cost)+'_Influences.node'\n",
    "            with open(txt_file, \"w\") as my_output_file:\n",
    "                with open(csv_file, \"r\") as my_input_file:\n",
    "                    [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "                my_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
